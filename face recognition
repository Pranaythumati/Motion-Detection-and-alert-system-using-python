import cv2
import os
import numpy as np



face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')




def capture_images(User):
    # Create a directory to store the captured images
    if not os.path.exists('Faces'):
        os.makedirs('Faces')

    # Open the camera
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("Error: Could not open video capture.")
        return

    # Set the image counter to 0
    count = 0

    while True:
        # Read a frame from the camera
        ret, frame = cap.read()
        if not ret:
            print("Error: Could not read frame.")
            break

        # Convert the frame to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect faces in the grayscale frame
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # Draw rectangles around the faces and store the images
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            # Store the captured face images in the Faces folder
            cv2.imwrite(f'Faces/{User}_{count}.jpg', gray[y:y + h, x:x + w])
            count += 1

        # Display the frame with face detection
        cv2.imshow('Capture Faces', frame)

        # Break the loop if the 'q' key is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        # Break the loop after capturing a certain number of images
        if count >= 300:
            break

    # Release the camera and close windows
    cap.release()
    cv2.destroyAllWindows()


def create_label_dict():
    label_dict = {}
    current_label = 0
    for file_name in os.listdir('Faces'):
        if file_name.endswith('.jpg'):
            name = file_name.split('_')[0]
            if name not in label_dict:
                label_dict[name] = current_label
                current_label += 1
    return label_dict

label = create_label_dict()

# Defining the Function to Train the Model
def train_model(label):
    # Create lists to store the face samples and their corresponding labels
    faces = []
    labels = []

    # Load the images from the 'Faces' folder
    for file_name in os.listdir('Faces'):
        if file_name.endswith('.jpg'):
            # Extract the label (person's name) from the file name
            name = file_name.split('_')[0]

            # Read the image and convert it to grayscale
            image = cv2.imread(os.path.join('Faces', file_name))
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

            # Detect faces in the grayscale image
            detected_faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

            # Check if a face is detected
            if len(detected_faces) > 0:
                # Crop the detected face region
                face_crop = gray[detected_faces[0][1]:detected_faces[0][1] + detected_faces[0][3],
                                 detected_faces[0][0]:detected_faces[0][0] + detected_faces[0][2]]

                # Append the face sample and label to the lists
                faces.append(face_crop)
                labels.append(label[name])

    # Train the face recognition model using the faces and labels
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.train(faces, np.array(labels))

    # Save the trained model to a file
    recognizer.save('trained_model.xml')
    return recognizer

# Train the model
Recognizer = train_model(label)



# Function to recognize faces from live video
def recognize_faces(recognizer, label):
    # Reverse the label dictionary for easy lookup
    label_reverse = {v: k for k, v in label.items()}

    # Open the camera
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("Error: Could not open video capture.")
        return

    while True:
        # Read a frame from the camera
        ret, frame = cap.read()
        if not ret:
            print("Error: Could not read frame.")
            break

        # Convert the frame to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect faces in the grayscale frame
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # Recognize faces in the frame
        for (x, y, w, h) in faces:
            face_crop = gray[y:y + h, x:x + w]
            label_id, confidence = recognizer.predict(face_crop)

            # Draw a rectangle around the face
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            # Display the label and confidence
            label_text = f"{label_reverse[label_id]} ({confidence:.2f})"
            cv2.putText(frame, label_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

        # Display the frame with recognized faces
        cv2.imshow('Recognize Faces', frame)

        # Break the loop if the 'q' key is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release the camera and close windows
    cap.release()
    cv2.destroyAllWindows()

# Recognize the live faces
recognize_faces(Recognizer, label)
